{"cells":[{"cell_type":"markdown","source":["<a href=\"https://colab.research.google.com/github/IrisFDTD/AI-UNIZAR-course/blob/main/recurrent_networks/ai_unizar_course_recurrent_neural_networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"],"metadata":{"id":"YIneca0UYQmc"}},{"cell_type":"markdown","source":["<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\"><img alt=\"Licencia Creative Commons\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png\" /></a><br /><span xmlns:dct=\"http://purl.org/dc/terms/\" property=\"dct:title\">*Introducción a la inteligencia artificial: redes neuronales avanzadas con Tensorflow-Keras*</span> por <span xmlns:cc=\"http://creativecommons.org/ns#\" property=\"cc:attributionName\">Sergio Gutiérrez Rodrigo (sergut@unizar.es)</span> se distribuye bajo una <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\">Licencia Creative Commons Atribución-NoComercial-CompartirIgual 4.0 Internacional</a>."],"metadata":{"id":"XG9e-npYBL9o"}},{"cell_type":"markdown","source":["```\n","Sergio G Rodrigo\n","Departamento de Física Aplicada\n","Universidad de Zaragoza\n","Instituto de Nanociencia y Materiales de Aragón (INMA)\n","C/ Pedro Cerbuna, 12, 50009, Zaragoza, España\n","```\n","\n","\n","\n","\n"],"metadata":{"id":"j2H5UHGe1Uf8"}},{"cell_type":"markdown","source":["# **Advanced Neural Networks with TensorFlow-Keras**"],"metadata":{"id":"kbJnjUXlCUuh"}},{"cell_type":"markdown","source":["---\n","# **Time Series Prediction with Recurrent Neural Networks (RNN)**\n","---\n"],"metadata":{"id":"viJV9O8QdYsR"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"QYkCtaeUKiAH"},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","source":["# Auxiliary functions"],"metadata":{"id":"u8LCrU4JJpAf"}},{"cell_type":"code","source":["def plot_history(history):\n","    train_loss = history.history['loss']\n","    epochs = range(1, len(train_loss) + 1)\n","\n","    # Extract the validation loss values\n","    val_loss = history.history['val_loss']\n","\n","    # Plot the training loss and validation loss vs. epoch\n","    plt.rcParams.update({'font.size': 14})\n","    plt.plot(epochs, train_loss, label='Training Loss')\n","    plt.plot(epochs, val_loss, label='Validation Loss')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","    plt.show()\n","    pass\n","\n","\n","def plot_time_series(x,y_true,model,name_model='naive'):\n","    # Create the plot\n","    j=np.random.randint(x.shape[0])\n","    n_steps=x.shape[1]\n","    time=list(range(1, n_steps + 1))\n","\n","    series=x[j]\n","    true=y_true[j][0]\n","    if(name_model=='naive'):\n","      pred=x[j][n_steps-1][0]\n","    else:\n","      pred=model.predict(x[j].reshape(1, n_steps, 1))\n","    print(y_true.shape)\n","\n","    time_pred=list(range(n_steps + 1,n_steps + 1+pred.shape[0]))\n","\n","    print(\"MSE=\",tf.keras.losses.mean_squared_error([true],[pred]).numpy())\n","\n","    plt.rcParams.update({'font.size': 14})\n","    plt.plot(time,series,label='data')\n","    plt.plot(time_pred,true,'ro',label='target')\n","    plt.plot(time_pred,pred,'x',color='black',label=name_model)\n","    plt.xlabel(r'$t$ (time in a.u.)')\n","    plt.ylabel(r'$f(t)$')\n","    plt.grid(True)\n","    plt.legend(loc='upper left')\n","    # Show the plot\n","    plt.show()\n","    pass\n","\n","\n"],"metadata":{"id":"i1_B5HLBJoEu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lZwSDdYfOcTQ"},"source":["# Generating Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"__mWfAFLKj-O"},"outputs":[],"source":["def generate_time_series(batch_size, n_steps):\n","  '''\n","  Return 4 vectors of random numbers of length batch_size\n","  '''\n","  freq1, freq2, offsets1, offsets2 = np.random.rand(4, batch_size, 1)\n","  time = np.linspace(0, 1, n_steps)\n","  series = 0.5 * np.sin((time - offsets1) * (freq1 * 10 + 10)) # wave 1\n","  series += 0.2 * np.sin((time - offsets2) * (freq2 * 20 + 20)) # + wave 2\n","  series += 0.1 * (np.random.rand(batch_size, n_steps) - 0.5) # + noise\n","  return series[..., np.newaxis].astype(np.float32)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fLctsivT2D8c"},"outputs":[],"source":["#generate new data with targets of length 10\n","n_steps = 50\n","series = generate_time_series(10000, n_steps + 10)\n","X_train, Y_train = series[:7000, :n_steps], series[:7000, -10:, 0]\n","X_valid, Y_valid = series[7000:9000, :n_steps], series[7000:9000, -10:, 0]\n","X_test, Y_test = series[9000:, :n_steps], series[9000:, -10:, 0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RxCvEnn9jE-7"},"outputs":[],"source":["print(X_train.shape,Y_train.shape)"]},{"cell_type":"markdown","metadata":{"id":"h8s1duI5j37q"},"source":["# **Predicting One Timestep**"]},{"cell_type":"markdown","metadata":{"id":"p4t2nEcbOFg5"},"source":["## Baselines\n","We set the Baseline of our problem.\n","\n","\n","1.   Predicting the last value --> MSE 0.02\n","2.   Dense NN ('Adam', 20 Epochs)--> MSE 0.004\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NH7YHKZgVw9n"},"outputs":[],"source":["#BASELINE1\n","#we predict the last value from each series\n","y_pred = X_test[:, -1]\n","print('MSE: ')\n","np.mean(tf.keras.losses.mean_squared_error(Y_test, y_pred))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FQsYqZ1sWz50"},"outputs":[],"source":["plot_time_series(X_test,Y_test,model=None,name_model='naive')"]},{"cell_type":"markdown","metadata":{"id":"42GQ6hWj9ImI"},"source":["## Comparing Neurons\n"]},{"cell_type":"markdown","metadata":{"id":"S45h9PVB6QOz"},"source":["### Feedforward neuron"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KjzfusD_NdMp"},"outputs":[],"source":["\n","model1 = tf.keras.models.Sequential([\n","tf.keras.layers.Flatten(input_shape=[50, 1]),\n","tf.keras.layers.Dense(1)\n","])\n","\n","model1.summary()\n","model1.compile(loss='mse',\n","          optimizer='adam',\n","          metrics=['mae'])\n","\n","history1=model1.fit(X_train, Y_train[:,0], epochs=20, validation_data=(X_valid, Y_valid[:,0]))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v9BvEwvrsvhr"},"outputs":[],"source":["ypred=model1.predict(X_test)\n","np.mean(tf.keras.losses.mean_squared_error(Y_test, ypred))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nkdHYsi8lUDy"},"outputs":[],"source":["plot_history(history1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U7J-rJibaWAr"},"outputs":[],"source":["plot_time_series(X_test,Y_test,model=model1,name_model='FF neuron')"]},{"cell_type":"markdown","metadata":{"id":"L7mF-hfYOSKg"},"source":["### Single recursive cell\n","Now we will build a model with a single cell, the simplest there can be.\n","MSE--> 0.014\n","we beat the naive model, but not the dense network. Our model only has 3 parameters vs 51 in the other network. It is too simple."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9pOMdK5_OXKD"},"outputs":[],"source":["model2 = tf.keras.models.Sequential([\n","tf.keras.layers.SimpleRNN(1, input_shape=[None, 1])])\n","#by deafault, it will only return the last output, hyperbolic tangent activation\n","#initial sate is set to 0\n","\n","#We do not need to specify the length of the\n","#input sequences (unlike in the previous model), since a recurrent neural network can\n","#process any number of time steps (this is why we set the first input dimension to None)\n","model2.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4LUwlaAbQQhb"},"outputs":[],"source":["model2.compile(loss='mse',\n","          optimizer='adam',\n","          metrics=['mae'])\n","\n","history2=model2.fit(X_train, Y_train[:,0], epochs=20, validation_data=(X_valid, Y_valid[:,0]))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WYg74s0au2V8"},"outputs":[],"source":["ypred=model2.predict(X_test)\n","np.mean(tf.keras.losses.mean_squared_error(Y_test[:,0], ypred))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MKqFXCZ3dF8M"},"outputs":[],"source":["plot_history(history2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u-Eq9NYRdGvo"},"outputs":[],"source":["plot_time_series(X_test,Y_test,model=model2,name_model='Recursive cell')"]},{"cell_type":"markdown","metadata":{"id":"IPmeUKrP9WuT"},"source":["### LSTM"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GA13aw5I8vBK"},"outputs":[],"source":["model3 = tf.keras.models.Sequential([\n","tf.keras.layers.LSTM(1, input_shape=[None, 1])])\n","#by deafault, it will only return the last output, hyperbolic tangent activation\n","#initial sate is set to 0\n","\n","#We do not need to specify the length of the\n","#input sequences (unlike in the previous model), since a recurrent neural network can\n","#process any number of time steps (this is why we set the first input dimension to None)\n","model3.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K32fwjQ686Ku"},"outputs":[],"source":["model3.compile(loss='mse',\n","          optimizer='adam',\n","          metrics=['mae'])\n","\n","history3=model3.fit(X_train, Y_train[:,0], epochs=20, validation_data=(X_valid, Y_valid[:,0]))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ly8Fp32S9uz0"},"outputs":[],"source":["ypred=model3.predict(X_test)\n","np.mean(tf.keras.losses.mean_squared_error(Y_test, ypred))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pR2zLHEW-GRI"},"outputs":[],"source":["plot_history(history3)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GEn3CHVM6yP_"},"outputs":[],"source":["plot_time_series(X_test,Y_test,model=model3,name_model='LSTM cell')"]},{"cell_type":"markdown","metadata":{"id":"KFuEsad7-VcA"},"source":["### GRU"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z1W-D0Fk-UhD"},"outputs":[],"source":["model4 = tf.keras.models.Sequential([\n","tf.keras.layers.GRU(1, input_shape=[None, 1])])\n","#by deafault, it will only return the last output, hyperbolic tangent activation\n","#initial sate is set to 0\n","\n","#We do not need to specify the length of the\n","#input sequences (unlike in the previous model), since a recurrent neural network can\n","#process any number of time steps (this is why we set the first input dimension to None)\n","model4.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"My_il0JN-sJd"},"outputs":[],"source":["model4.compile(loss='mse',\n","          optimizer='adam',\n","          metrics=['mae'])\n","\n","history4=model4.fit(X_train, Y_train[:,0], epochs=20, validation_data=(X_valid, Y_valid[:,0]))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BOjoZPiW-z9a"},"outputs":[],"source":["ypred=model4.predict(X_test)\n","np.mean(tf.keras.losses.mean_squared_error(Y_test, ypred))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dPmQJYZd-1Xk"},"outputs":[],"source":["plot_history(history4)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d4Pko8v_62mb"},"outputs":[],"source":["plot_time_series(X_test,Y_test,model=model4,name_model='GRU cell')"]},{"cell_type":"markdown","metadata":{"id":"daA_Ihqf7NIq"},"source":["## Comparing Networks"]},{"cell_type":"markdown","metadata":{"id":"6Xm88tnK-8Gy"},"source":["###DNN"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"91pIQYS6MocD"},"outputs":[],"source":["model5 = tf.keras.models.Sequential([\n","tf.keras.layers.Flatten(input_shape=[50, 1]),\n","tf.keras.layers.Dense(20),\n","tf.keras.layers.Dense(20),\n","tf.keras.layers.Dense(1)\n","])\n","\n","model5.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"57_f9uPiNG6p"},"outputs":[],"source":["model5.compile(loss='mse',\n","          optimizer='adam',\n","          metrics=['mae'])\n","\n","history5=model5.fit(X_train, Y_train[:,0], epochs=20, validation_data=(X_valid, Y_valid[:,0]))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z59RGz7MNd-x"},"outputs":[],"source":["ypred=model5.predict(X_test)\n","np.mean(tf.keras.losses.mean_squared_error(Y_test, ypred))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HNg_dG6XNpR7"},"outputs":[],"source":["plot_history(history5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KDRUScE4EnWr"},"outputs":[],"source":["plot_time_series(X_test,Y_test,model=model5,name_model='DNN')"]},{"cell_type":"markdown","metadata":{"id":"FVz1ctVwd9uM"},"source":["### RNN Network\n","stack multiple layers of cells\n","MSE--> 0.0027 we beat the baseline!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5-YVJ8IZeBkd"},"outputs":[],"source":["model6 = tf.keras.models.Sequential([\n","tf.keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),\n","tf.keras.layers.SimpleRNN(20, return_sequences=True),\n","tf.keras.layers.SimpleRNN(1)\n","])\n","\n","model6.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mlbbu_88fBM0"},"outputs":[],"source":["model6.compile(loss='mse',\n","          optimizer='adam',\n","          metrics=['mae'])\n","\n","history6=model6.fit(X_train, Y_train[:,0], epochs=20, validation_data=(X_valid, Y_valid[:,0]))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZBovdvcsxDF7"},"outputs":[],"source":["ypred=model6.predict(X_test)\n","np.mean(tf.keras.losses.mean_squared_error(Y_test, ypred))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mzA0LlNfmQ1Z"},"outputs":[],"source":["plot_history(history6)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zc7-2Pu7eglM"},"outputs":[],"source":["plot_time_series(X_test,Y_test,model=model6,name_model='Deep RNN')"]},{"cell_type":"markdown","metadata":{"id":"zn_3aGP-fwvQ"},"source":["Make sure to set return_sequences=True for all recurrent layers\n","(except the last one, if you only care about the last output). If you\n","don’t, they will output a 2D array (containing only the output of\n","the last time step) instead of a 3D array (containing outputs for all\n","time steps), and the next recurrent layer will complain that you are\n","not feeding it sequences in the expected 3D format."]},{"cell_type":"markdown","metadata":{"id":"ygBKntn4hr66"},"source":["The last layer is not ideal:\n","\n","\n","1.   Cannot choose activation function\n","2.   it must have a single unit because we want to forecast\n","a univariate time series, and this means we must have a single output value per\n","time step. However, having a single unit means that the hidden state is just a single\n","number. That’s really not much, and it’s probably not that useful; presumably, the\n","RNN will mostly use the hidden states of the other recurrent layers to carry over all\n","the information it needs from time step to time step, and it will not use the final layer’s\n","hidden state very much\n","\n","We can use a Dense layer to solve this problems. MSE is similar, but it is more efficient.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F8erFRYSiOmL"},"outputs":[],"source":["model7 = tf.keras.models.Sequential([\n","tf.keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),\n","tf.keras.layers.SimpleRNN(20),\n","tf.keras.layers.Dense(1)\n","])\n","\n","model7.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PcHeI2I8i3hC"},"outputs":[],"source":["model7.compile(loss='mse',\n","          optimizer='adam',\n","          metrics=['mae'])\n","\n","history7=model7.fit(X_train, Y_train[:,0], epochs=20, validation_data=(X_valid, Y_valid[:,0]))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HJWsVt9PmVj3"},"outputs":[],"source":["plot_history(history7)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ft9jvitTfauA"},"outputs":[],"source":["plot_time_series(X_test,Y_test,model=model7,name_model='Deep RNN (output = dense layer)')"]},{"cell_type":"markdown","metadata":{"id":"O9vh4rOIkheA"},"source":["### LSTM Network"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q-YE0qE7k9RG"},"outputs":[],"source":["model8 = tf.keras.models.Sequential([\n","tf.keras.layers.LSTM(20, return_sequences=True, input_shape=[None, 1]),\n","tf.keras.layers.LSTM(20),\n","tf.keras.layers.Dense(1)\n","])\n","\n","model8.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jinGezV5lJwM"},"outputs":[],"source":["model8.compile(loss='mse',\n","          optimizer='adam',\n","          metrics=['mae'])\n","\n","history8=model8.fit(X_train, Y_train[:,0], epochs=20, validation_data=(X_valid, Y_valid[:,0]))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gta_1zMWlbsU"},"outputs":[],"source":["plot_history(history8)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZK2sfoGAlca3"},"outputs":[],"source":["plot_time_series(X_test,Y_test,model=model8,name_model='Deep LSTM')"]},{"cell_type":"markdown","metadata":{"id":"1Slg4M4ydMJN"},"source":["\n","\n","### GRU Network"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7RTJWlg2dSO5"},"outputs":[],"source":["model9 = tf.keras.models.Sequential([\n","tf.keras.layers.GRU(20, return_sequences=True, input_shape=[None, 1]),\n","tf.keras.layers.GRU(20),\n","tf.keras.layers.Dense(1)\n","])\n","\n","model9.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WGFmVbd5dchR"},"outputs":[],"source":["model9.compile(loss='mse',\n","          optimizer='adam',\n","          metrics=['mae'])\n","\n","history9=model9.fit(X_train, Y_train[:,0], epochs=20, validation_data=(X_valid, Y_valid[:,0]))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zhkkeM7xddIf"},"outputs":[],"source":["plot_history(history9)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xhtJLpFqdgdN"},"outputs":[],"source":["plot_time_series(X_test,Y_test,model=model9,name_model='Deep LSTM')"]},{"cell_type":"markdown","metadata":{"id":"5zovl0YNjcq-"},"source":["# **Forecasting Several timesteps**\n","We have three options:\n","\n","\n","1.   Forecast the next step, add it to the timeseriries, and repeat\n","2.   Have targets of 10 timesteps\n","3.   Use a sequence to sequence network and train it to give all steps at once\n","\n","We will try each one with the LSTM cell ,which is the one that has performed the best, to compare each of the methods\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jd79UtDYbC-2"},"outputs":[],"source":["def last_time_step_mse(y_true,y_pred):\n","  return tf.keras.metrics.mean_squared_error(y_true[:,-1],y_pred[:,-1])"]},{"cell_type":"markdown","metadata":{"id":"FR4QXF4uUX5A"},"source":["## Forecasting the next step iteratively\n"]},{"cell_type":"code","source":["model= model9 #Choose a previous model"],"metadata":{"id":"v1CNAdb6Y2Av"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T3TgklIvZeCr"},"outputs":[],"source":["#predict\n","n_pred=10\n","j = np.random.randint(0, len(Y_test))\n","\n","sequence=X_test[j].reshape(1,X_train.shape[1], 1)\n","for i in range (0,n_pred):\n","  pred=model.predict(sequence[:,i:,:]) #predict next timestep with previous 1000 steps\n","  sequence=np.concatenate((sequence, pred.reshape(1, 1, 1)), axis=1) #add it to the sequence\n","prediction=sequence[0,50:,:]\n","print(prediction)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O8YlTAiXg8d7"},"outputs":[],"source":["Y_test[j]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"95jX6d-tZ1LA"},"outputs":[],"source":["# Create the plot\n","j=np.random.randint(X_test.shape[0])\n","plt.rcParams.update({'font.size': 22})\n","plt.plot(list(range(1, n_steps + 1)),X_test[j],label='data')\n","plt.plot(list(range(n_steps + 1,n_steps + 11)),prediction,'x',color='black',label='Iterative')\n","plt.plot(list(range(n_steps + 1,n_steps + 11)),Y_test[j],'ro',label='targets')\n","plt.xlabel('Time')\n","plt.ylabel('y')\n","plt.grid(True)\n","plt.legend(loc='upper left')\n","# Show the plot\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"1LP4FNrMy9QF"},"source":["## Targets of longer length"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jd2caL91O2vC"},"outputs":[],"source":["model10 = tf.keras.models.Sequential([\n","tf.keras.layers.LSTM(20, return_sequences=True, input_shape=[None, 1]),\n","tf.keras.layers.LSTM(20),\n","tf.keras.layers.Dense(10)\n","])\n","model10.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e0Ch6hDTPCar"},"outputs":[],"source":["model10.compile(loss='mse',\n","          optimizer='adam',\n","          metrics='mae')\n","\n","history10=model10.fit(X_train, Y_train, epochs=20, validation_data=(X_valid, Y_valid))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x0sxlDUc7pGy"},"outputs":[],"source":["predictions=model10.predict(X_test)\n","predictions.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BwIhsUm2maA3"},"outputs":[],"source":["plot_history(history10)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e9d8viEaghkJ"},"outputs":[],"source":["# Create the plot\n","j=np.random.randint(X_test.shape[0])\n","pred=model10.predict(X_test[j].reshape(1, 50, 1))\n","print(pred)\n","plt.rcParams.update({'font.size': 22})\n","plt.plot(list(range(1, n_steps + 1)),X_test[j],label='data')\n","plt.plot(list(range(n_steps + 1,n_steps + 11)),Y_test[j],'ro',label='target')\n","plt.plot(list(range(n_steps + 1,n_steps + 11)),pred[0],'x',color='black',label='LSTM')\n","plt.xlabel('Time')\n","plt.ylabel('y')\n","\n","plt.grid(True)\n","plt.legend(loc='upper left')\n","\n","\n","# Show the plot\n","plt.show()\n","\n","plot_time_series(X_test,Y_test,model=model10,name_model='LSTM')\n"]},{"cell_type":"markdown","metadata":{"id":"sO2SCpkUUhZK"},"source":["## Sequence-to-sequence"]},{"cell_type":"markdown","metadata":{"id":"q6kwpXEVRFvo"},"source":["instead of training\n","the model to forecast the next 10 values only at the very last time step, we can\n","train it to forecast the next 10 values at each and every time step. In other words, we\n","can turn this sequence-to-vector RNN into a sequence-to-sequence RNN.\n","\n","\n","\n","1.   loss will contain a term for the output of the RNN at\n","each and every time step\n","2.   more error gradients flowing through the model, and they won’t have to\n","flow only through time; they will also flow from the output of each time step. This\n","will both stabilize and speed up training.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gEglDi_tTxos"},"outputs":[],"source":["#now, every target will contain n_steps vectors of dimension 10, each one shifted by 10 steps.\n","n_steps = 50\n","target_len=10\n","Y = np.empty((10000, n_steps, target_len)) # each target is a sequence of 10D vectors\n","for step_ahead in range(1, target_len + 1):\n","  Y[:, :, step_ahead - 1] = series[:, step_ahead:step_ahead + n_steps, 0]\n","Y_train = Y[:7000]\n","Y_valid = Y[7000:9000]\n","Y_test = Y[9000:]"]},{"cell_type":"markdown","metadata":{"id":"Yi_nEMPIU_k9"},"source":["It may be surprising that the targets will contain values that appear\n","in the inputs (there is a lot of overlap between X_train and\n","Y_train). Isn’t that cheating? Fortunately, not at all: at each time\n","step, the model only knows about past time steps, so it cannot look\n","ahead. It is said to be a causal model."]},{"cell_type":"markdown","metadata":{"id":"UcDzO1Hc8o0i"},"source":["### The model\n","\n","+ $W_x=n_{inputs} \\times n_{neurons}$\n","+ $W_y=n_{neurons} \\times n_{neurons}$\n","+ $b= n_{neurons}$"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L434pZksT_ni"},"outputs":[],"source":["\n","model11 = tf.keras.models.Sequential([\n","tf.keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),\n","tf.keras.layers.SimpleRNN(20, return_sequences=True),\n","tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(10))\n","])\n","\n","model11.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xTkyL7rPYW-_"},"outputs":[],"source":["#To compute we use MSE in all sequences, but we just want the last one, so we define:\n","def last_time_step_mse(Y_true, Y_pred):\n","  return tf.keras.metrics.mean_squared_error(Y_true[:, -1], Y_pred[:, -1])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T04VoupxY19v"},"outputs":[],"source":["optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n","model11.compile(loss=\"mse\", optimizer=optimizer, metrics=['mae'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"epQVHgMGZFXO"},"outputs":[],"source":["history11=model11.fit(X_train, Y_train, epochs=20, validation_data=(X_valid, Y_valid))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ChfMuAoqXzf8"},"outputs":[],"source":["predictions=model11.predict(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rVq-HbfGmgz3"},"outputs":[],"source":["plot_history(history11)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ryig1Lr_bMgu"},"outputs":[],"source":["# Create the plot\n","# Y_test = samples x time_steps x target_points\n","# Each Y_test[j] = time_steps x target_points\n","# Note that Y_test[j,:,i] is the function shifted i+1 steps ahead\n","# Y_test[j][-1] are the last target_points values of all the shifted functions\n","# By construction is the result of the problem\n","target_len=10\n","j=np.random.randint(X_test.shape[0])\n","pred=model11.predict(X_test[j].reshape(1, 50, 1))\n","print(X_test.shape)\n","print(Y_test.shape)\n","print(Y_test[j].shape)\n","print(pred.shape)\n","print(pred[0].shape)\n","plt.rcParams.update({'font.size': 22})\n","plt.plot(list(range(1, n_steps + 1)),X_test[j],label='data')\n","plt.plot(list(range(n_steps + 1,n_steps + target_len+1)),Y_test[j][-1],'ro',label='target')\n","plt.plot(list(range(n_steps + 1,n_steps + target_len+1)),pred[0][-1],'x',color='black',label='S2S LSTM')\n","plt.xlabel('Time')\n","plt.ylabel('y')\n","plt.grid(True)\n","plt.legend(loc='upper left')\n","\n","# Show the plot\n","plt.show()\n"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"116e9ZZ0MVA6cX2GhcXKgWgZP9sYnbNIg","timestamp":1696945923580}],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}